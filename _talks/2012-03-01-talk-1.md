---
title: "Training with label adversary"
collection: talks
type: "Talk"
permalink: /talks/2022-03-01-ideas-1
venue: "Lahore Pakistan"
date: 2021-11-04
location: "Lahore"
---

Since their advent, GANs have transformed the machine learning landscape. Everyday we see the impact it has both on the industry and the research
field. In this idea, I proposed a method inspired from GANs in which the training network is pitted against an adversary. The idea was to train a neural network
with the help from a label adversary. In GANs, generator produces an output which is then sent to the discriminator as an input. The role of the discriminator is to predict whether the input received is from the generator or the training data itself. The training stops when the discriminator is unable to differentiate
between the sources of the samples.
Based on the underlying idea of adversarial learning, I explore a different aspect of it. There are two networks at play here, namely the predictor and
the discriminator. The input provided to both the networks are from the training data itself. However, the task of the discriminator network is to predict
whether the N class output is coming from the dataset or the predictor network. The training process is similar to GANs, where the error is back propagated through
the discriminator and into the predictor network. Training proceeds until the discriminator cannot distinguish between the target label vector from the target data or the output label vector from the predictor network.

Rather than using hot targets in training, I used soft targets with added randomization while still maintaining the target class identity of the samples, to make
the task harder for the discriminator and to avoid over fitting.
In this idea, I also looked at how training with label adversaries can help in other areas of deep learning such as knowledge distillation, transfer learning
and model compression. While also keeping an eye on requirements such as training data size, computation time and hyper-parameters and their affect on
generalization. This might also help me shed some more light into the inner working of GANs.
The idea also extends the concept to multi-agent learning. Where more than one predictor network are pitted against the discriminator trying to fool it.
Later using auction as an example I highlight how this multi-agent adversarial learning might be helpful in the real world.
